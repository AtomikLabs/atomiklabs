name: Parse arXiv Summaries CI/CD

on:
  push:
    branches:
      - prod
      - stage
      - dev
    paths:
      - "services/parse_arxiv_summaries/**"
  pull_request:
    branches:
      - dev
    paths:
      - "services/parse_arxiv_summaries/**"
  workflow_dispatch:

jobs:
  parse_arxiv_summaries:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        id: checkout
        uses: actions/checkout@v4

      - name: Install jq
        id: install-jq
        run: sudo apt-get install jq

      - name: Read AtomikLabs config and Set Environment Variables
        id: read-config
        run: |
          config_file=".atomiklabs.json"
          echo "APP_NAME=$(jq -r '.app_name' "$config_file")" >> $GITHUB_ENV
          echo "AWS_REGION=$(jq -r '.infra.terraform_aws_region' "$config_file")" >> $GITHUB_ENV
          echo "DATA_INGESTION_KEY_PREFIX=$(jq -r '.services.data_ingestion.data_ingestion_key_prefix' "$config_file")" >> $GITHUB_ENV
          echo "ETL_KEY_PREFIX=$(jq -r '.etl.etl_key_prefix' "$config_file")" >> $GITHUB_ENV
          echo "INFRA_CONFIG_BUCKET=$(jq -r '.infra.infra_config_bucket' "$config_file")" >> $GITHUB_ENV
          echo "INFRA_CONFIG_BUCKET_ARN=$(jq -r '.infra.infra_config_bucket_arn' "$config_file")" >> $GITHUB_ENV
          echo "INFRA_CONFIG_PREFIX=$(jq -r '.infra.infra_config_prefix' "$config_file")" >> $GITHUB_ENV
          echo "OUTPUTS_PREFIX=$(jq -r '.infra.outputs_prefix' "$config_file")" >> $GITHUB_ENV
          echo "SERVICE_NAME=$(jq -r '.services.etl.parse_arxiv_summaries.service_name' "$config_file")" >> $GITHUB_ENV
          echo "SERVICE_VERSION=$(jq -r '.services.etl.parse_arxiv_summaries.service_version' "$config_file")" >> $GITHUB_ENV
          echo "TERRAFORM_OUTPUTS_PREFIX=$(jq -r '.infra.terraform_outputs_prefix' "$config_file")" >> $GITHUB_ENV

      - name: Install node and npm
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install NPM Dependencies
        run: |
          npm install

      - name: Load Environment Variables
        uses: ./.github/actions/load-env-variables

      - name: Get Git Commit SHA
        id: get-commit-sha
        run: |
          COMMIT_SHA=$(git rev-parse HEAD)
          echo "::set-output name=commit-sha::$COMMIT_SHA"

      - name: Increment Semver Version and Generate Tag
        id: increment-version
        run: |
          CURRENT_VERSION="${{ env.SERVICE_VERSION }}"
          SEMVER_REGEX="^(0|[1-9]\d*)\.(0|[1-9]\d*)\.(0|[1-9]\d*)(?:-((?:0|[1-9]\d*|\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\.(?:0|[1-9]\d*|\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\+([0-9a-zA-Z-]+(?:\.[0-9a-zA-Z-]+)*))?$"
          if [[ $CURRENT_VERSION =~ $SEMVER_REGEX ]]; then
            MAJOR="${BASH_REMATCH[1]}"
            MINOR="${BASH_REMATCH[2]}"
            PATCH="${BASH_REMATCH[3]}"
            NEW_PATCH=$((PATCH+1))
            NEW_VERSION="$MAJOR.$MINOR.$NEW_PATCH"
          else
            echo "Invalid semantic version format. Using default 1.0.0"
            NEW_VERSION="1.0.0"
          fi
          NEW_TAG="${{ env.ENV_NAME }}-${{ env.SERVICE_NAME }}-$NEW_VERSION-${{ steps.get-commit-sha.outputs.commit-sha }}"
          echo "::set-output name=new-version::$NEW_VERSION"
          echo "::set-output name=new-tag::$NEW_TAG"

      - name: Set AWS Credentials
        uses: ./.github/actions/set-aws-credentials
        with:
          ENVIRONMENT_NAME: ${{ env.ENV_NAME }}
          DEV_AWS_ACCESS_KEY_ID: ${{ secrets.DEV_AWS_ACCESS_KEY_ID }}
          DEV_AWS_SECRET_ACCESS_KEY: ${{ secrets.DEV_AWS_SECRET_ACCESS_KEY }}
          PROD_AWS_ACCESS_KEY_ID: ${{ secrets.PROD_AWS_ACCESS_KEY_ID }}
          PROD_AWS_SECRET_ACCESS_KEY: ${{ secrets.PROD_AWS_SECRET_ACCESS_KEY }}
          STAGE_AWS_ACCESS_KEY_ID: ${{ secrets.STAGE_AWS_ACCESS_KEY_ID }}
          STAGE_AWS_SECRET_ACCESS_KEY: ${{ secrets.STAGE_AWS_SECRET_ACCESS_KEY }}

      - name: Ensure S3 bucket exists
        id: ensure-s3-bucket-exists
        run: |
          if ! aws s3 ls "s3://${{ env.INFRA_CONFIG_BUCKET }}" 2>&1 | grep -q 'NoSuchBucket'; then
            echo "Bucket exists."
          else
            echo "Bucket does not exist. Creating bucket..."
            aws s3 mb "s3://${{ env.INFRA_CONFIG_BUCKET }}"
            aws s3api put-bucket-versioning --bucket atomiklabs-infra-config-bucket --versioning-configuration Status=Enabled
          fi

      - name: Ensure DynamoDB table exists
        id: ensure-dynamodb-table-exists
        run: |
          TABLE_NAME="atomiklabs-parse-arxiv-summaries-locks"
          REGION="${{ env.AWS_REGION }}"
          if aws dynamodb describe-table --table-name $TABLE_NAME 2>&1 | grep -q 'ResourceNotFoundException'; then
            echo "DynamoDB table does not exist. Creating table..."
            aws dynamodb create-table \
              --table-name $TABLE_NAME \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region $REGION
            echo "DynamoDB table created."
          else
            echo "DynamoDB table exists."
          fi

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.7.0

      - name: Set Terraform Variables from Environment File
        run: |
          jq -r 'to_entries|map("\(.key)=\(.value|tostring)")|.[]' ${{ env.ENV_FILE }} > env_vars
          while IFS= read -r line; do
            echo "$line" >> $GITHUB_ENV
          done < env_vars

      - name: Initialize Terraform
        run: terraform init -upgrade
        working-directory: ./infra/services/parse_arxiv_summaries

      - name: Fetch Terraform Outputs
        id: fetch-terraform-outputs
        run: |
          terraform_outputs_path="s3://${{ env.INFRA_CONFIG_BUCKET }}/terraform/${{ env.ENV_NAME }}-${{ env.TERRAFORM_OUTPUTS_PREFIX }}.json"
          aws s3 cp $terraform_outputs_path ./terraform_outputs.json
          echo "DATA_BUCKET=$(jq -r '.data_bucket.value' ./terraform_outputs.json)" >> $GITHUB_ENV
          echo "DATA_BUCKET_ARN=$(jq -r '.data_bucket_arn.value' ./terraform_outputs.json)" >> $GITHUB_ENV
          echo "DATA_CATALOG_DB_NAME=$(jq -r '.aws_glue_catalog_database_data_catalog_database_name.value' ./terraform_outputs.json)" >> $GITHUB_ENV
          echo "ECR_REPO_URL=$(jq -r '.ecr_repo_url.value' ./terraform_outputs.json)" >> $GITHUB_ENV
        env:
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: Check if Image Version Already Exists
        id: check-version
        run: |
          image_tag="${{ steps.increment-version.outputs.new-tag }}"
          set +e  # Disable exit on error
          image_exists=$(aws ecr describe-images --repository-name ${{ env.ENV_NAME }}-repository --image-ids imageTag=${image_tag} --region ${{ env.AWS_REGION }} 2>&1)
          result=$?
          set -e  # Re-enable exit on error
          if [ $result -eq 0 ]; then
            echo "::error::Image with tag ${image_tag} already exists. Please update the version."
            exit 1
          elif echo $image_exists | grep -q 'ImageNotFoundException'; then
            echo "Image tag ${image_tag} does not exist. Proceeding with build and push."
          else
            echo "::error::Unexpected error checking image existence: $image_exists"
            exit 1
          fi
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          REPO: ${{ env.REPO }}
          SERVICE_NAME: ${{ env.SERVICE_NAME }}
          SERVICE_VERSION: ${{ env.SERVICE_VERSION }}

      - name: Build, Tag and Push Fetch Daily Summaries Image
        id: build-tag-push-parse-arxiv-summaries
        run: |
          aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin 758145997264.dkr.ecr.us-east-1.amazonaws.com
          image_uri=$ECR_REPO_URL:${{ steps.increment-version.outputs.new-tag }}
          echo "IMAGE_URI=${image_uri}" >> $GITHUB_ENV
          docker build -t $image_uri -f services/parse_arxiv_summaries/Dockerfile .
          docker push $image_uri
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          ECR_REPO_URL: ${{ env.ECR_REPO_URL }}

      - name: Verify Image in ECR Repository
        id: verify-image
        run: |
          image_tag="${{ steps.increment-version.outputs.new-tag }}"
          repo_name="${{ env.ENV_NAME }}-repository"
          set +e  # Disable exit on error
          image_exists=$(aws ecr describe-images --repository-name $repo_name --image-ids imageTag=$image_tag --region ${{ env.AWS_REGION }} 2>&1)
          result=$?
          set -e  # Re-enable exit on error
          if [ $result -eq 0 ]; then
            echo "Image $image_tag found in ECR repository $repo_name."
          else
            if echo $image_exists | grep -q 'ImageNotFoundException'; then
              echo "::error::Image with tag $image_tag not found in ECR repository $repo_name after several retries. Exiting."
              exit 1
            else
              echo "::error::Unexpected error checking image existence: $image_exists"
              exit 1
            fi
          fi
        env:
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: Validate Terraform
        run: terraform validate
        working-directory: ./infra/services/parse_arxiv_summaries

      - name: Plan Terraform
        id: plan
        run: terraform plan -var-file="../../../${{ env.ENV_FILE }}"
        working-directory: ./infra/services/parse_arxiv_summaries
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
          TF_VAR_app_name: ${{ env.APP_NAME }}
          TF_VAR_aws_region: ${{ env.AWS_REGION }}
          TF_VAR_data_bucket: ${{ env.DATA_BUCKET }}
          TF_VAR_data_bucket_arn: ${{ env.DATA_BUCKET_ARN }}
          TF_VAR_data_catalog_db_name: ${{ env.DATA_CATALOG_DB_NAME }}
          TF_VAR_data_ingestion_key_prefix: ${{ env.DATA_INGESTION_KEY_PREFIX }}
          TF_VAR_environment: ${{ env.ENV_NAME }}
          TF_VAR_etl_key_prefix: ${{ env.ETL_KEY_PREFIX }}
          TF_VAR_image_uri: ${{ env.IMAGE_URI }}
          TF_VAR_service_name: ${{ env.SERVICE_NAME }}
          TF_VAR_service_version: ${{ steps.increment-version.outputs.new-version }}

      - name: Apply Terraform
        id: apply-terraform
        run: |
          echo "${{ env.ENV_FILE }}"
          echo "${{ env.AWS_REGION }}"
          terraform apply -var-file="../../../${{ env.ENV_FILE }}" -auto-approve
        working-directory: ./infra/services/parse_arxiv_summaries
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
          TF_VAR_app_name: ${{ env.APP_NAME }}
          TF_VAR_aws_region: ${{ env.AWS_REGION }}
          TF_VAR_data_bucket: ${{ env.DATA_BUCKET }}
          TF_VAR_data_bucket_arn: ${{ env.DATA_BUCKET_ARN }}
          TF_VAR_data_catalog_db_name: ${{ env.DATA_CATALOG_DB_NAME }}
          TF_VAR_data_ingestion_key_prefix: ${{ env.DATA_INGESTION_KEY_PREFIX }}
          TF_VAR_environment: ${{ env.ENV_NAME }}
          TF_VAR_etl_key_prefix: ${{ env.ETL_KEY_PREFIX }}
          TF_VAR_image_uri: ${{ env.IMAGE_URI }}
          TF_VAR_service_name: ${{ env.SERVICE_NAME }}
          TF_VAR_service_version: ${{ steps.increment-version.outputs.new-version }}

      - name: Save Terraform Outputs
        id: save-terraform-outputs
        run: |
          terraform output -json > terraform_outputs.json
          aws s3 cp terraform_outputs.json s3://${{ env.INFRA_CONFIG_BUCKET }}/${{ env.TERRAFORM_OUTPUTS_PREFIX }}/${{ env.ENV_NAME }}-${{ env.OUTPUTS_PREFIX }}-${{ env.SERVICE_NAME }}.json
        working-directory: ./infra/services/parse_arxiv_summaries

      - name: Update Fetch Daily Summaries Lambda Function
        id: update-parse-arxiv-summaries
        run: aws lambda update-function-code --function-name ${{ env.ENV_NAME }}-${{ env.SERVICE_NAME }} --image-uri ${{ env.IMAGE_URI }}
        env:
          ECR_REPO_URL: ${{ env.ECR_REPO_URL }}
          PARSE_ARXIV_SUMMARIES_ARN: ${{ env.PARSE_ARXIV_SUMMARIES_ARN }}
