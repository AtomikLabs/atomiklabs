name: AtomikLabs Fetch Daily Summaries CI/CD

on:
  push:
    branches:
      - prod
      - stage
      #- dev
    paths:
      - "services/fetch_daily_summaries/**"
  workflow_dispatch:

jobs:
  fetch_daily_summaries:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        id: checkout
        uses: actions/checkout@v4

      - name: Install jq
        id: install-jq
        run: sudo apt-get install jq

      - name: Read AtomikLabs config and Set Environment Variables
        id: read-config
        run: |
          config_file=".atomiklabs.json"
          echo "ARXIV_BASE_URL=$(jq -r '.data_ingestion.arxiv_base_url' "$config_file")" >> $GITHUB_ENV
          echo "ARXIV_SUMMARY_SET=$(jq -r '.data_ingestion.arxiv_summary_set' "$config_file")" >> $GITHUB_ENV
          echo "AWS_REGION=$(jq -r '.infra.terraform_aws_region' "$config_file")" >> $GITHUB_ENV
          echo "BASTION_HOST_KEY_PAIR_NAME=$(jq -r '.networking.bastion_host_key_pair_name' "$config_file")" >> $GITHUB_ENV
          echo "DATA_INGESTION_KEY_PREFIX=$(jq -r '.data_ingestion.data_ingestion_key_prefix' "$config_file")" >> $GITHUB_ENV
          echo "DATA_INGESTION_METADATA_KEY_PREFIX=$(jq -r '.metadata.data_ingestion_metadata_key_prefix' "$config_file")" >> $GITHUB_ENV
          echo "FETCH_DAILY_SUMMARIES_NAME=$(jq -r '.data_ingestion.fetch_daily_summaries_name' "$config_file")" >> $GITHUB_ENV
          echo "FETCH_DAILY_SUMMARIES_VERSION=$(jq -r '.data_ingestion.fetch_daily_summaries_version' "$config_file")" >> $GITHUB_ENV
          echo "INFRA_CONFIG_BUCKET=$(jq -r '.infra.infra_config_bucket' "$config_file")" >> $GITHUB_ENV
          echo "INFRA_CONFIG_BUCKET_ARN=$(jq -r '.infra.infra_config_bucket_arn' "$config_file")" >> $GITHUB_ENV
          echo "INFRA_CONFIG_PREFIX=$(jq -r '.infra.infra_config_prefix' "$config_file")" >> $GITHUB_ENV
          echo "BACKEND_DYNAMODB_TABLE=$(jq -r '.infra.backend_dynamodb_table' "$config_file")" >> $GITHUB_ENV
          echo "OUTPUTS_PREFIX=$(jq -r '.infra.outputs_prefix' "$config_file")" >> $GITHUB_ENV
          echo "REPO=$(jq -r '.infra.repo' "$config_file")" >> $GITHUB_ENV

      - name: Install node and npm
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install NPM Dependencies
        run: |
          npm install

      - name: Load Environment Variables
        uses: ./.github/actions/load-env-variables

      - name: Set RabbitMQ Credentials
        uses: ./.github/actions/set-rabbitmq-credentials

      - name: Set AWS Credentials
        uses: ./.github/actions/set-aws-credentials
        with:
          ENVIRONMENT_NAME: ${{ env.ENV_NAME }}
          PROD_AWS_ACCESS_KEY_ID: ${{ secrets.PROD_AWS_ACCESS_KEY_ID }}
          PROD_AWS_SECRET_ACCESS_KEY: ${{ secrets.PROD_AWS_SECRET_ACCESS_KEY }}
          STAGE_AWS_ACCESS_KEY_ID: ${{ secrets.STAGE_AWS_ACCESS_KEY_ID }}
          STAGE_AWS_SECRET_ACCESS_KEY: ${{ secrets.STAGE_AWS_SECRET_ACCESS_KEY }}
          DEV_AWS_ACCESS_KEY_ID: ${{ secrets.DEV_AWS_ACCESS_KEY_ID }}
          DEV_AWS_SECRET_ACCESS_KEY: ${{ secrets.DEV_AWS_SECRET_ACCESS_KEY }}

      - name: Ensure S3 bucket exists
        id: ensure-s3-bucket-exists
        run: |
          if ! aws s3 ls "s3://${{ env.INFRA_CONFIG_BUCKET }}" 2>&1 | grep -q 'NoSuchBucket'; then
            echo "Bucket exists."
          else
            echo "Bucket does not exist. Creating bucket..."
            aws s3 mb "s3://${{ env.INFRA_CONFIG_BUCKET }}"
            aws s3api put-bucket-versioning --bucket atomiklabs-infra-config-bucket --versioning-configuration Status=Enabled
          fi

      - name: Ensure DynamoDB table exists
        id: ensure-dynamodb-table-exists
        run: |
          TABLE_NAME="atomiklabs-terraform-locks"
          REGION="${{ env.AWS_REGION }}"
          if aws dynamodb describe-table --table-name $TABLE_NAME 2>&1 | grep -q 'ResourceNotFoundException'; then
            echo "DynamoDB table does not exist. Creating table..."
            aws dynamodb create-table \
              --table-name $TABLE_NAME \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region $REGION
            echo "DynamoDB table created."
          else
            echo "DynamoDB table exists."
          fi

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.7.0

      - name: Set Terraform Variables from Environment File
        run: |
          jq -r 'to_entries|map("\(.key)=\(.value|tostring)")|.[]' ${{ env.ENV_FILE }} > env_vars
          while IFS= read -r line; do
            echo "$line" >> $GITHUB_ENV
          done < env_vars

      - name: Initialize Terraform
        run: terraform init -upgrade
        working-directory: ./infra/core

      - name: Fetch Terraform Outputs
        id: fetch-terraform-outputs
        run: |
          terraform_outputs_path="s3://${{ env.INFRA_CONFIG_BUCKET }}/${{ env.INFRA_CONFIG_PREFIX }}/${{ env.ENV_NAME }}-${{ env.OUTPUTS_PREFIX }}.json"
          aws s3 cp $terraform_outputs_path ./terraform_outputs.json
          echo "FETCH_DAILY_SUMMARIES_ARN=$(jq -r '.aws_lambda_function_fetch_daily_summaries_arn.value' ./terraform_outputs.json)" >> $GITHUB_ENV
          echo "ECR_REPO_URL=$(jq -r '.aws_ecr_repository_repository_url.value' ./terraform_outputs.json)" >> $GITHUB_ENV
        env:
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: Check if Image Version Already Exists
        id: check-version
        run: |
          image_tag="${{ env.ENV_NAME }}-${{ env.FETCH_DAILY_SUMMARIES_NAME }}-${{ env.FETCH_DAILY_SUMMARIES_VERSION }}"
          set +e  # Disable exit on error
          image_exists=$(aws ecr describe-images --repository-name ${{ env.ENV_NAME }}-repository --image-ids imageTag=${image_tag} --region ${{ env.AWS_REGION }} 2>&1)
          result=$?
          set -e  # Re-enable exit on error
          if [ $result -eq 0 ]; then
            echo "::error::Image with tag ${image_tag} already exists. Please update the version."
            exit 1
          elif echo $image_exists | grep -q 'ImageNotFoundException'; then
            echo "Image tag ${image_tag} does not exist. Proceeding with build and push."
          else
            echo "::error::Unexpected error checking image existence: $image_exists"
            exit 1
          fi
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          REPO: ${{ env.REPO }}
          FETCH_DAILY_SUMMARIES_NAME: ${{ env.FETCH_DAILY_SUMMARIES_NAME }}
          FETCH_DAILY_SUMMARIES_VERSION: ${{ env.FETCH_DAILY_SUMMARIES_VERSION }}

      - name: Build, Tag and Push Fetch Daily Summaries Image
        id: build-tag-push-fetch-daily-summaries
        run: |
          aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin 758145997264.dkr.ecr.us-east-1.amazonaws.com
          image_name=$ECR_REPO_URL:${{ env.ENV_NAME }}-${FETCH_DAILY_SUMMARIES_NAME}-${FETCH_DAILY_SUMMARIES_VERSION}
          docker build -t ${image_name} -f services/fetch_daily_summaries/Dockerfile .
          docker push ${image_name}
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          ECR_REPO_URL: ${{ env.ECR_REPO_URL }}
          FETCH_DAILY_SUMMARIES_NAME: ${{ env.FETCH_DAILY_SUMMARIES_NAME}}
          FETCH_DAILY_SUMMARIES_VERSION: ${{ env.FETCH_DAILY_SUMMARIES_VERSION }}

      - name: Update Fetch Daily Summaries Lambda Function
        id: update-fetch-daily-summaries
        run: |
          image_name=$ECR_REPO_URL:${{ env.ENV_NAME }}-${FETCH_DAILY_SUMMARIES_NAME}-${FETCH_DAILY_SUMMARIES_VERSION}
          aws lambda update-function-code --function-name ${{ env.FETCH_DAILY_SUMMARIES_ARN }} --image-uri ${image_name}
        env:
          ECR_REPO_URL: ${{ env.ECR_REPO_URL }}
          FETCH_DAILY_SUMMARIES_ARN: ${{ env.FETCH_DAILY_SUMMARIES_ARN }}
          FETCH_DAILY_SUMMARIES_NAME: ${{ env.FETCH_DAILY_SUMMARIES_NAME }}
          FETCH_DAILY_SUMMARIES_VERSION: ${{ env.FETCH_DAILY_SUMMARIES_VERSION }}

      - name: Validate Terraform
        run: terraform validate
        working-directory: ./infra/core

      - name: Plan Terraform
        id: plan
        run: terraform plan -var-file="../../${{ env.ENV_FILE }}"
        working-directory: ./infra/core
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
          TF_VAR_alert_email: ${{ secrets.ALERT_EMAIL }}
          TF_VAR_arxiv_base_url: ${{ env.ARXIV_BASE_URL }}
          TF_VAR_arxiv_summary_set: ${{ env.ARXIV_SUMMARY_SET }}
          TF_VAR_aws_region: ${{ env.AWS_REGION }}
          TF_VAR_backend_dynamodb_table: ${{ env.BACKEND_DYNAMODB_TABLE }}
          TF_VAR_bastion_host_key_pair_name: ${{ env.BASTION_HOST_KEY_PAIR_NAME }}
          TF_VAR_data_ingestion_key_prefix: ${{ env.DATA_INGESTION_KEY_PREFIX }}
          TF_VAR_data_ingestion_metadata_key_prefix: ${{ env.DATA_INGESTION_METADATA_KEY_PREFIX }}
          TF_VAR_etl_key_prefix: ${{ env.ETL_KEY_PREFIX }}
          TF_VAR_fetch_daily_summaries_name: ${{ env.FETCH_DAILY_SUMMARIES_NAME }}
          TF_VAR_fetch_daily_summaries_version: ${{ env.FETCH_DAILY_SUMMARIES_VERSION }}
          TF_VAR_home_ip: ${{ secrets.HOME_IP }}
          TF_VAR_infra_config_bucket: ${{ env.INFRA_CONFIG_BUCKET }}
          TF_VAR_infra_config_bucket_arn: ${{ env.INFRA_CONFIG_BUCKET_ARN }}
          TF_VAR_infra_config_prefix: ${{ env.INFRA_CONFIG_PREFIX }}
          TF_VAR_outputs_prefix: ${{ env.OUTPUTS_PREFIX }}
          TF_VAR_rabbitmqctl_password: ${{ secrets.RABBITMQCTL_PASSWORD }}
          TF_VAR_rabbitmqctl_username: ${{ secrets.RABBITMQCTL_USERNAME }}
          TF_VAR_repo: ${{ env.REPO }}

      - name: Apply Terraform
        id: apply-terraform
        run: |
          echo "${{ env.ENV_FILE }}"
          echo "${{ env.AWS_REGION }}"
          terraform apply -var-file="../../${{ env.ENV_FILE }}" -auto-approve
        working-directory: ./infra/core
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
          TF_VAR_alert_email: ${{ secrets.ALERT_EMAIL }}
          TF_VAR_arxiv_base_url: ${{ env.ARXIV_BASE_URL }}
          TF_VAR_arxiv_summary_set: ${{ env.ARXIV_SUMMARY_SET }}
          TF_VAR_aws_region: ${{ env.AWS_REGION }}
          TF_VAR_backend_dynamodb_table: ${{ env.BACKEND_DYNAMODB_TABLE }}
          TF_VAR_bastion_host_key_pair_name: ${{ env.BASTION_HOST_KEY_PAIR_NAME }}
          TF_VAR_data_ingestion_key_prefix: ${{ env.DATA_INGESTION_KEY_PREFIX }}
          TF_VAR_data_ingestion_metadata_key_prefix: ${{ env.DATA_INGESTION_METADATA_KEY_PREFIX }}
          TF_VAR_etl_key_prefix: ${{ env.ETL_KEY_PREFIX }}
          TF_VAR_fetch_daily_summaries_name: ${{ env.FETCH_DAILY_SUMMARIES_NAME }}
          TF_VAR_fetch_daily_summaries_version: ${{ env.FETCH_DAILY_SUMMARIES_VERSION }}
          TF_VAR_home_ip: ${{ secrets.HOME_IP }}
          TF_VAR_infra_config_bucket: ${{ env.INFRA_CONFIG_BUCKET }}
          TF_VAR_infra_config_bucket_arn: ${{ env.INFRA_CONFIG_BUCKET_ARN }}s
          TF_VAR_infra_config_prefix: ${{ env.INFRA_CONFIG_PREFIX }}
          TF_VAR_outputs_prefix: ${{ env.OUTPUTS_PREFIX }}
          TF_VAR_rabbitmqctl_password: ${{ secrets.RABBITMQCTL_PASSWORD }}
          TF_VAR_rabbitmqctl_username: ${{ secrets.RABBITMQCTL_USERNAME }}
          TF_VAR_repo: ${{ env.REPO }}

      - name: Save Terraform Outputs
        id: save-terraform-outputs
        run: |
          terraform output -json > terraform_outputs.json
          aws s3 cp terraform_outputs.json s3://${{ env.INFRA_CONFIG_BUCKET }}/${{ env.INFRA_CONFIG_PREFIX }}/${{ env.ENV_NAME }}-${{ env.OUTPUTS_PREFIX }}-{{ env.FETCH_DAILY_SUMMARIES_NAME }}.json
        working-directory: ./infra/core
