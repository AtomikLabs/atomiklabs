name: Fetch Daily Summaries CI/CD

on:
  push:
    branches:
      - prod
      - stage
      - dev
    paths:
      - "services/fetch_daily_summaries/**"
  pull_request:
    branches:
      - dev
    paths:
      - "services/fetch_daily_summaries/**"
  workflow_dispatch:

jobs:
  fetch_daily_summaries:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10"]
    steps:
      - name: Checkout code
        id: checkout
        uses: actions/checkout@v4

      - name: Install jq
        id: install-jq
        run: sudo apt-get install jq

      - name: Read AtomikLabs config and Set Environment Variables
        id: read-config
        run: |
          config_file=".atomiklabs.json"
          echo "APP_NAME=$(jq -r '.app_name' "$config_file")" >> $GITHUB_ENV
          echo "ARXIV_BASE_URL=$(jq -r '.arxiv.arxiv_base_url' "$config_file")" >> $GITHUB_ENV
          echo "ARXIV_SUMMARY_SET=$(jq -r '.arxiv.arxiv_summary_set' "$config_file")" >> $GITHUB_ENV
          echo "AWS_REGION=$(jq -r '.infra.terraform_aws_region' "$config_file")" >> $GITHUB_ENV
          echo "BACKEND_DYNAMODB_TABLE=$(jq -r '.infra.backend_dynamodb_table' "$config_file")" >> $GITHUB_ENV
          echo "DATA_INGESTION_KEY_PREFIX=$(jq -r '.services.data_ingestion.data_ingestion_key_prefix' "$config_file")" >> $GITHUB_ENV
          echo "DATA_INGESTION_METADATA_KEY_PREFIX=$(jq -r '.metadata.data_ingestion_metadata_key_prefix' "$config_file")" >> $GITHUB_ENV
          echo "INFRA_CONFIG_BUCKET=$(jq -r '.infra.infra_config_bucket' "$config_file")" >> $GITHUB_ENV
          echo "INFRA_CONFIG_BUCKET_ARN=$(jq -r '.infra.infra_config_bucket_arn' "$config_file")" >> $GITHUB_ENV
          echo "INFRA_CONFIG_PREFIX=$(jq -r '.infra.infra_config_prefix' "$config_file")" >> $GITHUB_ENV
          echo "MAX_RETRIES=$(jq -r '.services.data_ingestion.fetch_daily_summaries.max_retries' "$config_file")" >> $GITHUB_ENV
          echo "OUTPUTS_PREFIX=$(jq -r '.infra.outputs_prefix' "$config_file")" >> $GITHUB_ENV
          echo "RUNTIME=$(jq -r '.services.data_ingestion.fetch_daily_summaries.runtime' "$config_file")" >> $GITHUB_ENV
          echo "SERVICE_NAME=$(jq -r '.services.data_ingestion.fetch_daily_summaries.service_name' "$config_file")" >> $GITHUB_ENV
          echo "SERVICE_VERSION=$(jq -r '.services.data_ingestion.fetch_daily_summaries.service_version' "$config_file")" >> $GITHUB_ENV
          echo "ZIP_PREFIX=$(jq -r '.services.zip_prefix' "$config_file")" >> $GITHUB_ENV
          echo "TERRAFORM_OUTPUTS_PREFIX=$(jq -r '.infra.terraform_outputs_prefix' "$config_file")" >> $GITHUB_ENV

      - name: Install node and npm
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install NPM Dependencies
        run: |
          npm install

      - name: Load Environment Variables
        uses: ./.github/actions/load-env-variables

      - name: Get Git Commit SHA
        id: get-commit-sha
        run: |
          COMMIT_SHA=$(git rev-parse HEAD)
          echo "::set-output name=commit-sha::$COMMIT_SHA"

      - name: Set AWS Credentials
        uses: ./.github/actions/set-aws-credentials
        with:
          ENVIRONMENT_NAME: ${{ env.ENV_NAME }}
          DEV_AWS_ACCESS_KEY_ID: ${{ secrets.DEV_AWS_ACCESS_KEY_ID }}
          DEV_AWS_SECRET_ACCESS_KEY: ${{ secrets.DEV_AWS_SECRET_ACCESS_KEY }}
          PROD_AWS_ACCESS_KEY_ID: ${{ secrets.PROD_AWS_ACCESS_KEY_ID }}
          PROD_AWS_SECRET_ACCESS_KEY: ${{ secrets.PROD_AWS_SECRET_ACCESS_KEY }}
          STAGE_AWS_ACCESS_KEY_ID: ${{ secrets.STAGE_AWS_ACCESS_KEY_ID }}
          STAGE_AWS_SECRET_ACCESS_KEY: ${{ secrets.STAGE_AWS_SECRET_ACCESS_KEY }}

      - name: Set NEO4J Credentials
        run: |
          credentials_arn=""

          if [ "${{ env.ENV_NAME }}" == "dev" ]; then
            credentials_arn="${{ secrets.AWS_DEV_NEO4J_CREDENTIALS }}"
          elif [ "${{ env.ENV_NAME }}" == "prod" ]; then
            credentials_arn="${{ secrets.AWS_PROD_NEO4J_CREDENTIALS }}"
          elif [ "${{ env.ENV_NAME }}" == "stage" ]; then
            credentials_arn="${{ secrets.AWS_STAGE_NEO4J_CREDENTIALS }}"
          elif [ "${{ env.ENV_NAME }}" == "test" ]; then
            credentials_arn="${{ secrets.AWS_TEST_NEO4J_CREDENTIALS }}"
          fi
          echo "NEO4J_CREDENTIALS_ARN=$credentials_arn" >> $GITHUB_ENV

      - name: Get neo4j secrets
        uses: aws-actions/aws-secretsmanager-get-secrets@v1
        with:
          secret-ids: |
            NEO4J_CREDS, ${{ env.NEO4J_CREDENTIALS_ARN }}
          parse-json-secrets: true

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Update Fetch Daily Summaries Lambda Function
        id: update-fetch-daily-summaries
        run: |
          mkdir build
          cp services/${{ env.SERVICE_NAME}}/src/requirements.txt build/
          cp services/${{ env.SERVICE_NAME}}/src/${{ env.SERVICE_NAME}}/lambda_handler.py build/
          cp services/${{ env.SERVICE_NAME}}/src/${{ env.SERVICE_NAME}}/storage_manager.py build/
          ls -la build
          cd build
          pip install -r requirements.txt -t .
          cd ..
          zip -r ${{ env.SERVICE_NAME}}.zip build/* -x build/__pycache__/**\*
          zip_key="${{ env.ZIP_PREFIX }}/${{ env.SERVICE_NAME}}.zip"
          echo "ZIP_KEY=$zip_key" >> $GITHUB_ENV
          aws s3 cp ${{ env.SERVICE_NAME}}.zip s3://${{ env.INFRA_CONFIG_BUCKET }}/${{ env.ZIP_PREFIX }}/${{ env.SERVICE_NAME}}.zip
        env:
          ECR_REPO_URL: ${{ env.ECR_REPO_URL }}
          FETCH_DAILY_SUMMARIES_ARN: ${{ env.FETCH_DAILY_SUMMARIES_ARN }}

      - name: Ensure S3 bucket exists
        id: ensure-s3-bucket-exists
        run: |
          if ! aws s3 ls "s3://${{ env.INFRA_CONFIG_BUCKET }}" 2>&1 | grep -q 'NoSuchBucket'; then
            echo "Bucket exists."
          else
            echo "Bucket does not exist. Creating bucket..."
            aws s3 mb "s3://${{ env.INFRA_CONFIG_BUCKET }}"
            aws s3api put-bucket-versioning --bucket atomiklabs-infra-config-bucket --versioning-configuration Status=Enabled
          fi

      - name: Ensure DynamoDB table exists
        id: ensure-dynamodb-table-exists
        run: |
          TABLE_NAME="atomiklabs-fetch-daily-summaries-locks"
          REGION="${{ env.AWS_REGION }}"
          if aws dynamodb describe-table --table-name $TABLE_NAME 2>&1 | grep -q 'ResourceNotFoundException'; then
            echo "DynamoDB table does not exist. Creating table..."
            aws dynamodb create-table \
              --table-name $TABLE_NAME \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region $REGION
            echo "DynamoDB table created."
          else
            echo "DynamoDB table exists."
          fi

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.7.0

      - name: Set Terraform Variables from Environment File
        run: |
          jq -r 'to_entries|map("\(.key)=\(.value|tostring)")|.[]' ${{ env.ENV_FILE }} > env_vars
          while IFS= read -r line; do
            echo "$line" >> $GITHUB_ENV
          done < env_vars

      - name: Initialize Terraform
        run: terraform init -upgrade
        working-directory: ./infra/services/fetch_daily_summaries

      - name: Fetch Terraform Outputs
        id: fetch-terraform-outputs
        run: |
          terraform_outputs_path="s3://${{ env.INFRA_CONFIG_BUCKET }}/terraform/${{ env.ENV_NAME }}-${{ env.TERRAFORM_OUTPUTS_PREFIX }}.json"
          aws s3 cp $terraform_outputs_path ./terraform_outputs.json
          echo "DATA_BUCKET=$(jq -r '.data_bucket.value' ./terraform_outputs.json)" >> $GITHUB_ENV
          echo "DATA_BUCKET_ARN=$(jq -r '.data_bucket_arn.value' ./terraform_outputs.json)" >> $GITHUB_ENV
          echo "DATA_CATALOG_DB_NAME=$(jq -r '.aws_glue_catalog_database_data_catalog_database_name.value' ./terraform_outputs.json)" >> $GITHUB_ENV
          echo "METADATA_TABLE_NAME=$(jq -r '.aws_glue_catalog_table_data_catalog_table_data_ingestion_metadata_table_name.value' ./terraform_outputs.json)" >> $GITHUB_ENV
          echo "NEO4J_URI=$(jq -r '.neo4j_instance_private_ip.value' ./terraform_outputs.json)" >> $GITHUB_ENV
          echo "ECR_REPO_URL=$(jq -r '.ecr_repo_url.value' ./terraform_outputs.json)" >> $GITHUB_ENV
        env:
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: Validate Terraform
        run: terraform validate
        working-directory: ./infra/services/fetch_daily_summaries

      - name: Plan Terraform
        id: plan
        run: terraform plan -var-file="../../../${{ env.ENV_FILE }}"
        working-directory: ./infra/services/fetch_daily_summaries
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
          TF_VAR_app_name: ${{ env.APP_NAME }}
          TF_VAR_arxiv_base_url: ${{ env.ARXIV_BASE_URL }}
          TF_VAR_arxiv_summary_set: ${{ env.ARXIV_SUMMARY_SET }}
          TF_VAR_aws_region: ${{ env.AWS_REGION }}
          TF_VAR_data_bucket: ${{ env.DATA_BUCKET }}
          TF_VAR_data_bucket_arn: ${{ env.DATA_BUCKET_ARN }}
          TF_VAR_data_ingestion_key_prefix: ${{ env.DATA_INGESTION_KEY_PREFIX }}
          TF_VAR_environment: ${{ env.ENV_NAME }}
          TF_VAR_infra_config_bucket: ${{ env.INFRA_CONFIG_BUCKET }}
          TF_VAR_max_retries: ${{ env.MAX_RETRIES }}
          TF_VAR_neo4j_password: ${{ env.NEO4J_CREDS_NEO4J_PASSWORD }}
          TF_VAR_neo4j_uri: ${{ env.NEO4J_URI}}
          TF_VAR_neo4j_username: ${{ env.NEO4J_CREDS_NEO4J_USERNAME }}
          TF_VAR_runtime: ${{ env.RUNTIME }}
          TF_VAR_service_name: ${{ env.SERVICE_NAME }}
          TF_VAR_service_version: ${{ env.SERVICE_VERSION }}
          TF_VAR_zip_key: ${{ env.ZIP_KEY }}

      - name: Apply Terraform
        id: apply-terraform
        run: |
          echo "${{ env.ENV_FILE }}"
          echo "${{ env.AWS_REGION }}"
          terraform apply -var-file="../../../${{ env.ENV_FILE }}" -auto-approve
        working-directory: ./infra/services/fetch_daily_summaries
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
          TF_VAR_app_name: ${{ env.APP_NAME }}
          TF_VAR_arxiv_base_url: ${{ env.ARXIV_BASE_URL }}
          TF_VAR_arxiv_summary_set: ${{ env.ARXIV_SUMMARY_SET }}
          TF_VAR_aws_region: ${{ env.AWS_REGION }}
          TF_VAR_data_bucket: ${{ env.DATA_BUCKET }}
          TF_VAR_data_bucket_arn: ${{ env.DATA_BUCKET_ARN }}
          TF_VAR_data_ingestion_key_prefix: ${{ env.DATA_INGESTION_KEY_PREFIX }}
          TF_VAR_environment: ${{ env.ENV_NAME }}
          TF_VAR_infra_config_bucket: ${{ env.INFRA_CONFIG_BUCKET }}
          TF_VAR_max_retries: ${{ env.MAX_RETRIES }}
          TF_VAR_neo4j_password: ${{ env.NEO4J_CREDS_NEO4J_PASSWORD }}
          TF_VAR_neo4j_uri: ${{ env.NEO4J_URI}}
          TF_VAR_neo4j_username: ${{ env.NEO4J_CREDS_NEO4J_USERNAME }}
          TF_VAR_runtime: ${{ env.RUNTIME }}
          TF_VAR_service_name: ${{ env.SERVICE_NAME }}
          TF_VAR_service_version: ${{ env.SERVICE_VERSION }}
          TF_VAR_zip_key: ${{ env.ZIP_KEY }}

      - name: Save Terraform Outputs
        id: save-terraform-outputs
        run: |
          terraform output -json > terraform_outputs.json
          aws s3 cp terraform_outputs.json s3://${{ env.INFRA_CONFIG_BUCKET }}/${{ env.TERRAFORM_OUTPUTS_PREFIX }}/${{ env.ENV_NAME }}-${{ env.OUTPUTS_PREFIX }}-${{ env.SERVICE_NAME }}.json
        working-directory: ./infra/services/fetch_daily_summaries
